{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 80: Lab 01\n",
    "\n",
    "### Due Date: Tuesday January 14, Midnight (11:59 PM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding work will be developed in an accompanying `lab01.py` file, that will be imported into the current notebook.\n",
    "\n",
    "Labs and programming assignments will be graded in (at most) two ways:\n",
    "1. The functions and classes in the accompanying python file will be tested (a la DSC 20),\n",
    "2. The notebook will be graded (for graphs and free response questions).\n",
    "\n",
    "**Do not change the function names in the `*.py` file**\n",
    "- The functions in the `*.py` file are how your assignment is graded, and they are graded by their name. The dictionary at the end of the file (`GRADED FUNCTIONS`) contains the \"grading list\". The final function in the file allows your doctests to check that all the necessary functions exist.\n",
    "- If you changed something you weren't supposed to, just use git to revert!\n",
    "\n",
    "**Tips for working in the Notebook**:\n",
    "- The notebooks serve to present you the questions and give you a place to present your results for later review.\n",
    "- The notebook on *lab assignments* are not graded (only the `.py` file).\n",
    "- Notebooks for PAs will serve as a final report for the assignment, and contain conclusions and answers to open ended questions that are graded.\n",
    "- The notebook serves as a nice environment for 'pre-development' and experimentation before designing your function in your `.py` file.\n",
    "\n",
    "**Tips for developing in the .py file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional functions to solve the lab! \n",
    "    - Developing in python usually consists of larger files, with many short functions.\n",
    "    - You may write your other functions in an additional `.py` file that you import in `lab01.py` (much like we do in the notebook).\n",
    "- Always document your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing code from `lab**.py`\n",
    "\n",
    "* We import our `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab**.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab**.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab**.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab**` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.0.1-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.1 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2017.2\n",
      "  Downloading pytz-2019.3-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[K     |████████████████████████████████| 509 kB 55.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Collecting numpy>=1.13.3\n",
      "  Downloading numpy-1.18.1-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.1 MB 50.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Installing collected packages: pytz, numpy, pandas\n",
      "Successfully installed numpy-1.18.1 pandas-1.0.1 pytz-2019.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab01 as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 0 (EXAMPLE):**\n",
    "\n",
    "Write a function that takes in a possibly empty list of integers and:\n",
    "* Returns `True` if there exist two adjacent list elements that are consecutive integers.\n",
    "* Otherwise, returns `False`.\n",
    "\n",
    "For example, because `9` is next to `8`:\n",
    "```\n",
    ">>> lab.consecutive_ints([5,3,6,4,9,8])\n",
    "True\n",
    "```\n",
    "Whereas:\n",
    "```\n",
    ">>> lab.consecutive_ints([1,3,5,7,9])\n",
    "False\n",
    "```\n",
    "\n",
    "*Note*: This question is done for you, to demonstrate a completed homework problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code here (or in an IDE) if you'd like.\n",
    "# Though only code in lab01.py will be graded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more cells if you'd like!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your code in two ways:\n",
    "1. Run the cell below to test your code. You should also copy the cell and change the input to test further (i.e. write your own doctests)! Does it work for corner cases? Real-world data is **very messy** and you should expect your data processing code to break without thorough testing!\n",
    "2. Run doctests on `lab01.py` by running the following command on the commandline:\n",
    "```\n",
    "python -m doctest lab01.py\n",
    "```\n",
    "If the doctests pass, then there should be *no* output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test your code!\n",
    "lab.consecutive_ints([1,3,2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.consecutive_ints([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.consecutive_ints([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 1 (median):**\n",
    "\n",
    "Write a function called *median* that takes a non-empty list of numbers, returning the median element of the list. If the list has even length, it should return the mean of the two elements in the middle. Do not use any imported libraries for this question; you may use any built-in function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this\n",
    "lab.median([0, -1, 1, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 2 (List Distances):**\n",
    "\n",
    "Similar to Question 0, write a function that takes in a possibly empty list of integers and:\n",
    "* Returns `True` if there exist two list elements $i$ places apart, whose distance as integers is also $i$.\n",
    "* Otherwise, returns `False`.\n",
    "\n",
    "Assume your inputs tend to satisfy the condition, and the pair(s) saitifying the condition tend to be close together; design your function to run faster for this case. (Optimizing your code for an assumed distribution of incoming data is very common in data science).\n",
    "\n",
    "For example, because `3` and (the second) `5` are two places apart, and $|3-5| = 2$:\n",
    "```\n",
    ">>> lab.same_diff_ints([5,3,1,5,9,8])\n",
    "True\n",
    "```\n",
    "Whereas:\n",
    "```\n",
    ">>> lab.same_diff_ints([1,3,5,7,9])\n",
    "False\n",
    "```\n",
    "\n",
    "*Note*: Make sure to define some extreme test cases. Use the `%time` command to time your function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 99 µs, sys: 33 µs, total: 132 µs\n",
      "Wall time: 111 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time lab.same_diff_ints([5,3,1,5,9,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Strings and Files\n",
    "\n",
    "The following questions will help you (re)learn the basics of working with strings and reading data from files (which are read in as strings, by default)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 3 (Prefixes):**\n",
    "\n",
    "Write a function `prefixes` that takes a string and returns a string of every consecutive prefix of the input string. For example, `prefixes('Data!')` should return `'DDaDatDataData!'`.  (See the doctests for more examples).\n",
    "\n",
    "Recall that [strings may be sliced](https://docs.python.org/3/tutorial/introduction.html#strings), like lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DDaDatDataData!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.prefixes('Data!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 4 (Evens reversed):**\n",
    "\n",
    "Write a function `evens_reversed` that takes in a non-negative integer $N$ and returns a string containing all even integers from $1$ to $N$ (inclusive) in reversed order, separated by spaces. Additionally, [zero pad](https://www.tutorialspoint.com/python/string_zfill.htm) each integer, so that each has the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6 4 2'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.evens_reversed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[Recall](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files) that the built-in function `open` takes in a file path and returns *a file object* (sometimes called a *file handle*). Below are a few properties of file objects:\n",
    "\n",
    "* `open(path)` opens the file at location `path` for reading.\n",
    "* `open(path)` is an *iterable*, which contains successive lines of the file.\n",
    "* Once a file object is opened, after use it should be closed to avoid memory leaks. To ensure a file is closed once done, you should use a *context manager* as follows:\n",
    "```\n",
    "with open(path) as fh:\n",
    "    for line in fh:\n",
    "        process_line(line)\n",
    "```\n",
    "* To read the entire file into a string, use the read method:\n",
    "```\n",
    "with open(path) as fh:\n",
    "    s = fh.read()\n",
    "```\n",
    "However, you should be careful when reading an entire file into memory that the file isn't too big! *You should avoid this whenever possible!*\n",
    "\n",
    "**Question 5 (Reading Files):**\n",
    "\n",
    "Create a function `last_chars` that takes a file object and returns a string consisting of the last character of the line.\n",
    "\n",
    "*Remark:* A newline is the \"delimiter\" of the lines of a file, and doesn't count as part of the line (as the tests imply). Every other character is part of the line. For more info on this, see [the interpretation](https://en.wikipedia.org/wiki/Newline#Interpretation) of files as a 'newline delimited variables' file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hrg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'chars.txt')\n",
    "lab.last_chars(open(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## `numpy` exercises\n",
    "\n",
    "For an introduction to arrays and `numpy` recall the relevant section of [DSC 10](https://www.inferentialthinking.com/chapters/05/1/Arrays.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6 (Basic Arrays):**\n",
    "\n",
    "Create the following functions using `numpy` methods satisfying the requirements given in each part. Your solutions should **not** contain any loops or list comprehensions.\n",
    "\n",
    "* A function `arr_1` that takes in a `numpy` array and adds to each element the square-root of the index of each element.\n",
    "\n",
    "* A function `arr_2` that takes in a `numpy` array of integers and returns a boolean array (i.e. an array of booleans) whose `ith` element is `True` if and only if the `ith` element of the input array is divisble by 16.\n",
    "\n",
    "* A function `arr_3` that takes in a `numpy` array of [stock prices](https://en.wikipedia.org/wiki/Stock) per share on successive days in USD and returns an array of growth rates. That is, the `ith` number of the output array should contain the rate of growth in stock price between the $i^{th}$ day to the $(i+1)^{th}$ day. The growth rate should be a proportion, rounded to the nearest hundredth.\n",
    "\n",
    "* Suppose:\n",
    "    - `A` is a `numpy` array of [stock prices](https://en.wikipedia.org/wiki/Stock) per share for a company on successive days in USD \n",
    "    - you start with \\\\$20, and put aside \\\\$20 at the end of each day to buy as much stock as possible the following day. \n",
    "    - Any money left-over after a given day is saved for possibly buying stock on a future day. \n",
    "    - Create a function `arr_4` that takes in `A` and returns the day on which you can buy at least one share from 'left-over' money. If this never happens, return `-1`. The first stock purchase occurs on day 0. *Note: you cannot buy fractions of a share of stock*.\n",
    "    \n",
    "*Example:* If the stock price is \\\\$3 every day, then the answer is 'day 1':\n",
    "* day 0: buy 6 shares; \\\\$2 left-over; \\\\$22 at end of day.\n",
    "* day 1: buy 7 shares; \\\\$1 left-over; \\\\$21 at end of day.\n",
    "This is more than the 6 shares that \\\\$20 can buy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.89,  9.87,  9.97,  9.83,  9.86,  9.9 ,  9.86, 10.05, 10.14,\n",
       "       10.38, 10.51, 10.58, 10.6 , 10.62, 10.7 , 10.69, 10.61, 10.59,\n",
       "       10.62, 10.48, 10.54, 10.54, 10.52, 10.68, 10.71, 10.78, 10.74,\n",
       "       10.79, 10.94, 10.76, 10.82, 10.87, 10.72, 10.86, 10.88, 10.85,\n",
       "       10.79, 10.9 , 11.19, 11.12, 11.1 , 11.23, 11.3 , 11.33, 11.35,\n",
       "       11.32, 11.42, 11.52, 11.51, 11.53, 11.73, 11.63, 11.56, 11.71,\n",
       "       11.61, 11.74, 11.95, 11.89, 11.75, 11.74, 11.8 , 11.81, 11.79,\n",
       "       11.8 , 11.96, 11.95, 12.04, 12.01, 12.12, 12.22, 12.31, 12.29,\n",
       "       12.25, 12.37, 12.38, 12.4 , 12.61, 12.39, 12.38, 12.47, 12.5 ,\n",
       "       12.63, 12.77, 12.73, 12.48, 12.33, 12.26, 12.11, 11.99, 12.01,\n",
       "       12.11, 12.18, 12.27, 12.25, 12.25, 12.2 , 12.11, 12.26, 12.41,\n",
       "       12.45])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'stocks.csv')\n",
    "stocks = np.array([float(x) for x in open(fp)])\n",
    "stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   9.89,   10.87,   13.97,   18.83,   25.86,   34.9 ,   45.86,\n",
       "         59.05,   74.14,   91.38,  110.51,  131.58,  154.6 ,  179.62,\n",
       "        206.7 ,  235.69,  266.61,  299.59,  334.62,  371.48,  410.54,\n",
       "        451.54,  494.52,  539.68,  586.71,  635.78,  686.74,  739.79,\n",
       "        794.94,  851.76,  910.82,  971.87, 1034.72, 1099.86, 1166.88,\n",
       "       1235.85, 1306.79, 1379.9 , 1455.19, 1532.12, 1611.1 , 1692.23,\n",
       "       1775.3 , 1860.33, 1947.35, 2036.32, 2127.42, 2220.52, 2315.51,\n",
       "       2412.53, 2511.73, 2612.63, 2715.56, 2820.71, 2927.61, 3036.74,\n",
       "       3147.95, 3260.89, 3375.75, 3492.74, 3611.8 , 3732.81, 3855.79,\n",
       "       3980.8 , 4107.96, 4236.95, 4368.04, 4501.01, 4636.12, 4773.22,\n",
       "       4912.31, 5053.29, 5196.25, 5341.37, 5488.38, 5637.4 , 5788.61,\n",
       "       5941.39, 6096.38, 6253.47, 6412.5 , 6573.63, 6736.77, 6901.73,\n",
       "       7068.48, 7237.33, 7408.26, 7581.11, 7755.99, 7933.01, 8112.11,\n",
       "       8293.18, 8476.27, 8661.25, 8848.25, 9037.2 , 9228.11, 9421.26,\n",
       "       9616.41, 9813.45])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = lab.arr_1(stocks)\n",
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(out1 >= stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False,  True, False])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2 = lab.arr_2(np.array([1, 2, 16, 17, 32, 33]))\n",
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2.dtype == np.dtype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.  ,  0.01, -0.01,  0.  ,  0.  , -0.  ,  0.02,  0.01,  0.02,\n",
       "        0.01,  0.01,  0.  ,  0.  ,  0.01, -0.  , -0.01, -0.  ,  0.  ,\n",
       "       -0.01,  0.01,  0.  , -0.  ,  0.02,  0.  ,  0.01, -0.  ,  0.  ,\n",
       "        0.01, -0.02,  0.01,  0.  , -0.01,  0.01,  0.  , -0.  , -0.01,\n",
       "        0.01,  0.03, -0.01, -0.  ,  0.01,  0.01,  0.  ,  0.  , -0.  ,\n",
       "        0.01,  0.01, -0.  ,  0.  ,  0.02, -0.01, -0.01,  0.01, -0.01,\n",
       "        0.01,  0.02, -0.01, -0.01, -0.  ,  0.01,  0.  , -0.  ,  0.  ,\n",
       "        0.01, -0.  ,  0.01, -0.  ,  0.01,  0.01,  0.01, -0.  , -0.  ,\n",
       "        0.01,  0.  ,  0.  ,  0.02, -0.02, -0.  ,  0.01,  0.  ,  0.01,\n",
       "        0.01, -0.  , -0.02, -0.01, -0.01, -0.01, -0.01,  0.  ,  0.01,\n",
       "        0.01,  0.01, -0.  ,  0.  , -0.  , -0.01,  0.01,  0.01,  0.  ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3 = lab.arr_3(stocks)\n",
    "out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3.max() == 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out4 = lab.arr_4(np.array([3, 3, 3, 3]))\n",
    "out4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Getting Started with Pandas\n",
    "\n",
    "The following questions will help you get comfortable with Pandas. These questions are similar to questions on tables in DSC 10; review the [textbook](https://www.inferentialthinking.com) as necessary. As always for Pandas questions:\n",
    "1. Avoid writing loops through the rows of the dataset to do the problem, and\n",
    "2. Test the output/correctness of your code with the help of the dataset given, but be sure your code will also run on data \"like\" the dataset given (sampling rows using the `.sample` method is useful for this!).\n",
    "\n",
    "**Question 7 (Pandas basics):**\n",
    "\n",
    "Read in the file `movies_by_year.csv` in the `data` directory and understand the dataset by answering the following questions. To do this, create a function `movie_stats` that takes in a dataframe like `movies` and returns a series containing the following statistics:\n",
    "* The number of years covered by the dataset (`num_years`).\n",
    "* The total number of movies made over all years in the dataset (`tot_movies`).\n",
    "* The year with the fewest number of movies made; a tie should return the earliest year (`yr_fewest_movies`).\n",
    "* The average amount of money grossed over all the years in the dataset (`avg_gross`).\n",
    "* The year with the highest gross *per movie* (`highest_per_movie`).\n",
    "* The name of the top movie during the second-lowest (total) grossing year (`second_lowest`).\n",
    "* The average number of movies made the year *after* a Harry Potter movie was the #1 movie (`avg_after_harry`).\n",
    "\n",
    "The index of the output series are given in parenthesis above.\n",
    "\n",
    "*Note*: Your function should work on a dataset of the same format that contains information from other years. You may assume that none of the answers involving ranking returns a tie.\n",
    "\n",
    "*Note*: To make sure your function still runs, in the event that one of the 7 parts throws an exception (e.g. due to a very incorrect answer), use `Try... Except...` structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Total Gross</th>\n",
       "      <th>Number of Movies</th>\n",
       "      <th>#1 Movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>11128.5</td>\n",
       "      <td>702</td>\n",
       "      <td>Star Wars: The Force Awakens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>10360.8</td>\n",
       "      <td>702</td>\n",
       "      <td>American Sniper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>10923.6</td>\n",
       "      <td>688</td>\n",
       "      <td>Catching Fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>10837.4</td>\n",
       "      <td>667</td>\n",
       "      <td>The Avengers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>10174.3</td>\n",
       "      <td>602</td>\n",
       "      <td>Harry Potter / Deathly Hallows (P2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010</td>\n",
       "      <td>10565.6</td>\n",
       "      <td>536</td>\n",
       "      <td>Toy Story 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009</td>\n",
       "      <td>10595.5</td>\n",
       "      <td>521</td>\n",
       "      <td>Avatar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008</td>\n",
       "      <td>9630.7</td>\n",
       "      <td>608</td>\n",
       "      <td>The Dark Knight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2007</td>\n",
       "      <td>9663.8</td>\n",
       "      <td>631</td>\n",
       "      <td>Spider-Man 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2006</td>\n",
       "      <td>9209.5</td>\n",
       "      <td>608</td>\n",
       "      <td>Dead Man's Chest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2005</td>\n",
       "      <td>8840.5</td>\n",
       "      <td>547</td>\n",
       "      <td>Revenge of the Sith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2004</td>\n",
       "      <td>9380.5</td>\n",
       "      <td>551</td>\n",
       "      <td>Shrek 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2003</td>\n",
       "      <td>9239.7</td>\n",
       "      <td>506</td>\n",
       "      <td>Return of the King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2002</td>\n",
       "      <td>9155.0</td>\n",
       "      <td>479</td>\n",
       "      <td>Spider-Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2001</td>\n",
       "      <td>8412.5</td>\n",
       "      <td>482</td>\n",
       "      <td>Harry Potter / Sorcerer's Stone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2000</td>\n",
       "      <td>7661.0</td>\n",
       "      <td>478</td>\n",
       "      <td>The Grinch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1999</td>\n",
       "      <td>7448.0</td>\n",
       "      <td>461</td>\n",
       "      <td>The Phantom Menace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1998</td>\n",
       "      <td>6949.0</td>\n",
       "      <td>509</td>\n",
       "      <td>Saving Private Ryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1997</td>\n",
       "      <td>6365.9</td>\n",
       "      <td>510</td>\n",
       "      <td>Titanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1996</td>\n",
       "      <td>5911.5</td>\n",
       "      <td>471</td>\n",
       "      <td>Independence Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1995</td>\n",
       "      <td>5493.5</td>\n",
       "      <td>411</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1994</td>\n",
       "      <td>5396.2</td>\n",
       "      <td>453</td>\n",
       "      <td>Forrest Gump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1993</td>\n",
       "      <td>5154.2</td>\n",
       "      <td>462</td>\n",
       "      <td>Jurassic Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1992</td>\n",
       "      <td>4871.0</td>\n",
       "      <td>480</td>\n",
       "      <td>Aladdin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1991</td>\n",
       "      <td>4803.2</td>\n",
       "      <td>458</td>\n",
       "      <td>Terminator 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1990</td>\n",
       "      <td>5021.8</td>\n",
       "      <td>410</td>\n",
       "      <td>Home Alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1989</td>\n",
       "      <td>5033.4</td>\n",
       "      <td>502</td>\n",
       "      <td>Batman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1988</td>\n",
       "      <td>4458.4</td>\n",
       "      <td>510</td>\n",
       "      <td>Rain Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1987</td>\n",
       "      <td>4252.9</td>\n",
       "      <td>509</td>\n",
       "      <td>Three Men and a Baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1986</td>\n",
       "      <td>3778.0</td>\n",
       "      <td>451</td>\n",
       "      <td>Top Gun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1985</td>\n",
       "      <td>3749.2</td>\n",
       "      <td>470</td>\n",
       "      <td>Back to the Future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1984</td>\n",
       "      <td>4031.0</td>\n",
       "      <td>536</td>\n",
       "      <td>Beverly Hills Cop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1983</td>\n",
       "      <td>3766.0</td>\n",
       "      <td>495</td>\n",
       "      <td>Return of the Jedi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1982</td>\n",
       "      <td>3453.0</td>\n",
       "      <td>428</td>\n",
       "      <td>E.T.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Total Gross  Number of Movies                             #1 Movie\n",
       "0   2015      11128.5               702         Star Wars: The Force Awakens\n",
       "1   2014      10360.8               702                      American Sniper\n",
       "2   2013      10923.6               688                        Catching Fire\n",
       "3   2012      10837.4               667                         The Avengers\n",
       "4   2011      10174.3               602  Harry Potter / Deathly Hallows (P2)\n",
       "5   2010      10565.6               536                          Toy Story 3\n",
       "6   2009      10595.5               521                               Avatar\n",
       "7   2008       9630.7               608                      The Dark Knight\n",
       "8   2007       9663.8               631                         Spider-Man 3\n",
       "9   2006       9209.5               608                     Dead Man's Chest\n",
       "10  2005       8840.5               547                  Revenge of the Sith\n",
       "11  2004       9380.5               551                              Shrek 2\n",
       "12  2003       9239.7               506                   Return of the King\n",
       "13  2002       9155.0               479                           Spider-Man\n",
       "14  2001       8412.5               482      Harry Potter / Sorcerer's Stone\n",
       "15  2000       7661.0               478                           The Grinch\n",
       "16  1999       7448.0               461                   The Phantom Menace\n",
       "17  1998       6949.0               509                  Saving Private Ryan\n",
       "18  1997       6365.9               510                              Titanic\n",
       "19  1996       5911.5               471                     Independence Day\n",
       "20  1995       5493.5               411                            Toy Story\n",
       "21  1994       5396.2               453                         Forrest Gump\n",
       "22  1993       5154.2               462                        Jurassic Park\n",
       "23  1992       4871.0               480                              Aladdin\n",
       "24  1991       4803.2               458                         Terminator 2\n",
       "25  1990       5021.8               410                           Home Alone\n",
       "26  1989       5033.4               502                               Batman\n",
       "27  1988       4458.4               510                             Rain Man\n",
       "28  1987       4252.9               509                 Three Men and a Baby\n",
       "29  1986       3778.0               451                              Top Gun\n",
       "30  1985       3749.2               470                   Back to the Future\n",
       "31  1984       4031.0               536                    Beverly Hills Cop\n",
       "32  1983       3766.0               495                   Return of the Jedi\n",
       "33  1982       3453.0               428                                 E.T."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_fp = os.path.join('data', 'movies_by_year.csv')\n",
    "movies = pd.read_csv(movie_fp)\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['Year'].nunique()\n",
    "movies['Number of Movies'].sum()\n",
    "movies['Number of Movies'].min()\n",
    "movies.loc[movies['Number of Movies'] == movies['Number of Movies'].min()]['Year'].values[0]\n",
    "movies['Total Gross'].mean()\n",
    "avg = movies['Total Gross']/movies['Number of Movies']\n",
    "avg.max()\n",
    "movies.nsmallest(2, 'Total Gross')['#1 Movie'].values[0]\n",
    "hp = movies.loc[movies['#1 Movie'].str.contains('Harry Potter')]['Year']\n",
    "total = 0\n",
    "for i in np.arange(len(hp)):\n",
    "    year = hp.values[i]+1\n",
    "    total += movies.loc[movies['Year'] == year]['Number of Movies'].values[0]\n",
    "total/len(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_years                 34\n",
       "tot_movies             17834\n",
       "yr_fewest_movies        1990\n",
       "avg_gross            7226.91\n",
       "highest_per_movie    20.3369\n",
       "second_lowest           E.T.\n",
       "avg_after_harry          573\n",
       "dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = lab.movie_stats(movies)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(out, pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'num_years' in out.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(out.loc['second_lowest'], str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## CSV Files\n",
    "\n",
    "**Question 8 (Reading malformed csv files):**\n",
    "\n",
    "`malformed.csv` contains a file of comma-separated values, containing the following fields:\n",
    "\n",
    "\n",
    "|column name|description|type|\n",
    "|---|---|---|\n",
    "|first|first name of person|str|\n",
    "|last|last name of person|str|\n",
    "|weight|weight of person (lbs)|float|\n",
    "|height|height of person (in)|float|\n",
    "|geo|location of person; comma-separated latitude/longitude|str|\n",
    "\n",
    "Unfortunately, the entries contains errors that cause the Pandas `read_csv` function to fail parsing the file with the default settings. Instead, you must read in the file manually using Python's built-in `open` function.\n",
    "\n",
    "Clean the csv file into a Pandas DataFrame with columns as described in the table above, by creating a function called `parse_malformed` that takes in a file path and returns a parsed, properly-typed dataframe. The dataframe should contain columns as described in the table above (with the specified types); it should agree with `pd.read_csv` when the lines are not malformed.\n",
    "\n",
    "\n",
    "*Note:* Assume that the given csv file is a sample of a larger file; you will be graded against a **different** sample of the larger file that has the same type of parsing errors. That is, you should **not** hard-code your cleaning of the data to specific errors on specific lines in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Julia', 'Wagner', '142.0', '86.0', '\"39.8', '15.4\"']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_fp = os.path.join('data', 'malformed.csv')\n",
    "mf = open(mf_fp)\n",
    "mf.readline()[:-1].split(\",\")\n",
    "mf.readline()[:-1].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angelica,Rija,155.0,56.0,\"38.2,-71.7\"\n",
      "\n",
      "Tyler,Micajah,116.0,73.0\",\"38.0,6.9\"\n",
      "\n",
      "Kathleen,Nakea,163.0,69.0,\"36.3,-86.8\"\n",
      "\n",
      "Axel,Ronit,95.0,74.0,\"36.8,128.2\"\n",
      "\n",
      "Amiya,Kyona,130.0,72.0,\"36.3,114.5\"\n",
      "\n",
      "Torrey,Joshuacaleb,105.0,79.0,\"38.3,145.1\"\n",
      "\n",
      "Mariah,Alese,149.0,68.0,\"36.1,45.7\"\n",
      "\n",
      "Grayson,Daimen,140.0,80.0\",\"38.1,-72.6\"\n",
      "\n",
      "Yvette,Trayce,179.0,67.0,\"36.9,-8.3\"\n",
      "\n",
      "Cody,Hatim,150.0,63.0,\"38.0,-7.3\"\n",
      "\n",
      "Marissa,Daud,135.0,58.0,\"37.3,11.0\"\n",
      "\n",
      "Logan,Cristel,133.0,67.0,\"35.5,-110.2\"\n",
      "\n",
      "Kaiyah,Brinden,187.0,82.0,\"34.8,83.2\"\n",
      "\n",
      "Ivan,Devyne,193.0,54.0,\"36.6,262.0\"\n",
      "\n",
      "Shamaria,Aldrick\",139.0,73.0,\"38.5,-94.6\"\n",
      "\n",
      "Travis,Anavictoria,117.0,62.0,\"36.3,69.5\"\n",
      "\n",
      "Kennedy,Dalynn,171.0\",77.0,\"37.3,-27.5\"\n",
      "\n",
      "Alina,Danniell,105.0,55.0,\"37.4,314.7\"\n",
      "\n",
      "Cameron,Angelica,139.0,56.0,\"38.8,-79.3\"\n",
      "\n",
      "Madison,Barkley,120.0\",69.0,\"38.2,86.1\"\n",
      "\n",
      "Jackson,Taylr,113.0,78.0,\"36.7,56.7\"\n",
      "\n",
      "Agustin,Stephanye,91.0,62.0,\"36.4,54.5\"\n",
      "\n",
      "Janesha,Jhayla,143.0,64.0,\"35.9,-70.5\"\n",
      "\n",
      "Nickolas,Karenna,159.0,75.0,\"35.9,-73.9\"\n",
      "\n",
      "Stacy,Meaghen,149.0,68.0,\"36.6,-27.7\"\n",
      "\n",
      "Matthew,Kalis,166.0,66.0,\"37.8,0.2\"\n",
      "\n",
      "Rayona,Treniece,151.0,59.0,\"37.2,140.1\"\n",
      "\n",
      "Jack,Hanai,164.0,70.0,\"38.6,-63.6\"\n",
      "\n",
      "Hayley,Zsazsa,146.0\",62.0,\"36.2,-2.6\"\n",
      "\n",
      "Jacqueline,Treyten,164.0,73.0\",\"37.1,-56.1\"\n",
      "\n",
      "Anthony,Janaysia,127.0,,77.0,\"39.1,93.6\"\n",
      "\n",
      "Saige\",Kalieb,144.0,61.0,\"38.2,16.2\"\n",
      "\n",
      "Tiffany,Jamire,160.0,87.0,\"37.6,155.0\"\n",
      "\n",
      "Nichole,Derryk,134.0,66.0,\"36.9,-52.0\"\n",
      "\n",
      "Litzi,Keairah\",137.0,69.0,\"36.8,182.4\"\n",
      "\n",
      "Timothy,Montrice,151.0,65.0,\"36.7,69.2\"\n",
      "\n",
      "Alicia,Lilijana,161.0\",77.0,\"37.2,56.9\"\n",
      "\n",
      "Margaret,Ruthie,143.0,65.0,\"36.7,69.2\"\n",
      "\n",
      "Javier,Allycia\",121.0\",71.0,\"37.3,79.6\"\n",
      "\n",
      "Melanie,Vincent,112.0,60.0,\"37.3,123.5\"\n",
      "\n",
      "Jesus,Brennden,145.0,75.0,\"38.6,-43.4\"\n",
      "\n",
      "John,Zyon,115.0,77.0,\"38.1,-106.3\"\n",
      "\n",
      "David,Aubrea,122.0,62.0,\"38.0,-21.9\"\n",
      "\n",
      "Wesley,Laniece,165.0,68.0,\"37.2,71.2\"\n",
      "\n",
      "Lindsey,Alima,79.0,66.0,\"36.2,-61.4\"\n",
      "\n",
      "Kenneth,Kimo,124.0\",54.0,\"37.0,49.6\"\n",
      "\n",
      "Lauryn,Milia\",133.0,62.0,\"37.7,113.6\"\n",
      "\n",
      "Ryan\",Elleanor,149.0\",68.0,\"37.0,-32.3\n",
      "\n",
      "Keyara,Rozlyn,148.0,70.0,\"37.5,74.6\"\n",
      "\n",
      "Tyree,Windy,128.0,80.0,\"36.9,83.6\"\n",
      "\n",
      "Tori,Adithi,187.0,68.0,\"35.5,-12.4\"\n",
      "\n",
      "Carolina,Cecille,154.0,71.0,\"38.6,12.4\"\n",
      "\n",
      "Emmanuel,Leidi,112.0,61.0,\"37.6,64.6\"\n",
      "\n",
      "Andrew,Vikrant,90.0,61.0,\"36.6,36.9\"\n",
      "\n",
      "Donovan,Randa,120.0\",73.0,\"36.5,28.2\"\n",
      "\n",
      "Rachel\",Alexiz,145.0,67.0,\"38.0,36.4\"\"\n",
      "\n",
      "Dylan\",Aryon,104.0,65.0,\"35.0,18.0\"\n",
      "\n",
      "Jeevan,Ardit,148.0,71.0,\"36.9,-58.9\"\n",
      "\n",
      "Kaitlin,Isrrael,108.0,78.0,\"36.2,16.0\"\n",
      "\n",
      "Vanessa,Guiselle,96.0,77.0,\"38.0,86.0\"\n",
      "\n",
      "Alyssa,Gillian,88.0,69.0,\"38.2,252.0\"\n",
      "\n",
      "Christina,Jerard,178.0,77.0\",\"38.2,-57.5\"\n",
      "\n",
      "Hayli,Marton,125.0,73.0,\"37.7,-93.7\"\n",
      "\n",
      "Isabella,Laverne,117.0,76.0,\"36.4,88.1\"\n",
      "\n",
      "Parker,Kerly,160.0,59.0,\"36.7,139.3\"\n",
      "\n",
      "Madeleine,Amritpal,166.0,58.0,\"36.2,51.4\"\n",
      "\n",
      "Keaton,Kinzy,119.0,64.0\",\"36.4,20.5\"\n",
      "\n",
      "Mercedes,Tarika,129.0,70.0,\"37.0,-56.8\"\n",
      "\n",
      "Dallen,Keshae,127.0,75.0,\"37.1,-113.1\"\n",
      "\n",
      "Shay,Marcea,103.0,65.0,\"36.0,-33.1\"\n",
      "\n",
      "Adrianna,Karsten,157.0,81.0,\"34.8,36.1\"\n",
      "\n",
      "Max,Nairi,113.0\",67.0,\"36.9,12.2\"\n",
      "\n",
      "Suzanne,Dearion,129.0,70.0,\"36.9,-70.4\"\n",
      "\n",
      "Camryn,Tasnim,126.0,63.0,\"36.5,19.8\"\n",
      "\n",
      "Cielo,Saylah,103.0,65.0,\"36.1,83.1\"\n",
      "\n",
      "Annastasia,Averi,91.0,67.0,\"37.1,-43.7\"\n",
      "\n",
      "Hannah,Jerit,142.0,53.0,\"36.6,10.3\"\n",
      "\n",
      "Jovita,Marquaveon,150.0,70.0,\"38.2,-32.6\"\"\n",
      "\n",
      "Jasmine,Jahmal\",107.0,72.0,\"38.5,9.1\"\n",
      "\n",
      "Cheyenne,Gerrid,55.0,71.0,\"36.6,68.2\"\n",
      "\n",
      "Karma\",Nameer,131.0,65.0,\"37.5,69.8\"\n",
      "\n",
      "Madeline,Cira,128.0,65.0,\"37.4,149.6\"\n",
      "\n",
      "Connor,Sheridyn,141.0,73.0,\"36.8,-80.7\"\n",
      "\n",
      "Sarah,Sunday,180.0,54.0,\"36.7,-5.6\"\n",
      "\n",
      "Victoria,Maliik,164.0,60.0,\"36.3,151.2\n",
      "\n",
      "George,Tyshonna,105.0,74.0,\"37.5,-91.5\"\n",
      "\n",
      "Marquis,Kylar,137.0,51.0,\"38.2,228.4\"\n",
      "\n",
      "Marlene,Fatuma,117.0,64.0,\"36.4,-9.5\"\n",
      "\n",
      "Kathryn,Diondra,149.0,65.0,\"38.3,68.0\"\n",
      "\n",
      "Jonathan,Jersey,107.0,77.0,\"36.0,11.8\"\n",
      "\n",
      "Joshua,Caileen,,181.0,67.0,\"37.3,79.0\"\n",
      "\n",
      "Emily,Leonid,146.0,57.0,\"37.8,-68.7\",\n",
      "\n",
      "Jacqualyn,Angelea,116.0,63.0,\"36.4,-31.5\"\n",
      "\n",
      "Gionna,Pamala,180.0,79.0,\"38.6,-28.6\"\"\n",
      "\n",
      "Yasmeen,Jahron,135.0,84.0,\"38.3,-127.3\"\"\n",
      "\n",
      "Meghan,Carlyann,101.0,66.0,\"36.6,80.5\"\n",
      "\n",
      "Tess,Shree,146.0,,68.0,\"38.8,64.9\"\n",
      "\n",
      "Maria,Kalvyn,115.0,51.0,\"37.1,-90.4\"\n",
      "\n",
      "Lexie,Cheyenna,151.0,71.0,\"35.9,86.1\"\n",
      "\n",
      "\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "while True:\n",
    "        line = mf.readline()\n",
    "        print(line)\n",
    "        count += 1\n",
    "        if line == '':\n",
    "            break\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Julia</td>\n",
       "      <td>Wagner</td>\n",
       "      <td>142.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>39.8,15.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Angelica</td>\n",
       "      <td>Rija</td>\n",
       "      <td>155.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>38.2,-71.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tyler</td>\n",
       "      <td>Micajah</td>\n",
       "      <td>116.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>38.0,6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kathleen</td>\n",
       "      <td>Nakea</td>\n",
       "      <td>163.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>36.3,-86.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Axel</td>\n",
       "      <td>Ronit</td>\n",
       "      <td>95.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>36.8,128.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Yasmeen</td>\n",
       "      <td>Jahron</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>38.3,-127.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Meghan</td>\n",
       "      <td>Carlyann</td>\n",
       "      <td>101.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>36.6,80.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Tess</td>\n",
       "      <td>Shree</td>\n",
       "      <td>146.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>38.8,64.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Maria</td>\n",
       "      <td>Kalvyn</td>\n",
       "      <td>115.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>37.1,-90.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Lexie</td>\n",
       "      <td>Cheyenna</td>\n",
       "      <td>151.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>35.9,86.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       first      last  weight  height          geo\n",
       "0      Julia    Wagner   142.0    86.0    39.8,15.4\n",
       "1   Angelica      Rija   155.0    56.0   38.2,-71.7\n",
       "2      Tyler   Micajah   116.0    73.0     38.0,6.9\n",
       "3   Kathleen     Nakea   163.0    69.0   36.3,-86.8\n",
       "4       Axel     Ronit    95.0    74.0   36.8,128.2\n",
       "..       ...       ...     ...     ...          ...\n",
       "95   Yasmeen    Jahron   135.0    84.0  38.3,-127.3\n",
       "96    Meghan  Carlyann   101.0    66.0    36.6,80.5\n",
       "97      Tess     Shree   146.0    68.0    38.8,64.9\n",
       "98     Maria    Kalvyn   115.0    51.0   37.1,-90.4\n",
       "99     Lexie  Cheyenna   151.0    71.0    35.9,86.1\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = lab.parse_malformed(mf_fp)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['first', 'last', 'weight', 'height', 'geo']\n",
    "list(df.columns) == cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['last'].dtype == np.dtype('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['height'].dtype == np.dtype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['geo'].str.contains(',').all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) == 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yvette</td>\n",
       "      <td>Trayce</td>\n",
       "      <td>179.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>36.9,-8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cody</td>\n",
       "      <td>Hatim</td>\n",
       "      <td>150.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>38.0,-7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Marissa</td>\n",
       "      <td>Daud</td>\n",
       "      <td>135.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>37.3,11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Logan</td>\n",
       "      <td>Cristel</td>\n",
       "      <td>133.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>35.5,-110.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      first     last  weight  height          geo\n",
       "9    Yvette   Trayce   179.0    67.0    36.9,-8.3\n",
       "10     Cody    Hatim   150.0    63.0    38.0,-7.3\n",
       "11  Marissa     Daud   135.0    58.0    37.3,11.0\n",
       "12    Logan  Cristel   133.0    67.0  35.5,-110.2"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[9:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg = pd.read_csv(mf_fp, nrows=4, skiprows=10, names=cols)\n",
    "dg.index = range(9, 13)\n",
    "(dg == df.iloc[9:13]).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yvette</td>\n",
       "      <td>Trayce</td>\n",
       "      <td>179.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>36.9,-8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cody</td>\n",
       "      <td>Hatim</td>\n",
       "      <td>150.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>38.0,-7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Marissa</td>\n",
       "      <td>Daud</td>\n",
       "      <td>135.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>37.3,11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Logan</td>\n",
       "      <td>Cristel</td>\n",
       "      <td>133.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>35.5,-110.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      first     last  weight  height          geo\n",
       "9    Yvette   Trayce   179.0    67.0    36.9,-8.3\n",
       "10     Cody    Hatim   150.0    63.0    38.0,-7.3\n",
       "11  Marissa     Daud   135.0    58.0    37.3,11.0\n",
       "12    Logan  Cristel   133.0    67.0  35.5,-110.2"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done!\n",
    "\n",
    "* Submit the lab on Gradescope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.check_for_graded_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
